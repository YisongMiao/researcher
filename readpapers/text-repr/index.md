# Reading List for Text Representation



1. GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding. ICLR'19 Alex Wang1 , Amanpreet Singh1 , Julian Michael2 , Felix Hill3 , Omer Levy2 & Samuel R. Bowman1 [Local copy](files/glue.pdf)
2. Multi-Task Deep Neural Networks for Natural Language Understanding. ACL'19 Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao. [Local copy](files/MT-DNN.pdf)
3. Predicting ConceptNet Path Quality Using Crowdsourced Assessments of Naturalness. Yilun Zhou, Steven Schockaert, Julie A. Shah. [Local copy](files/www19-conceptnet.pdf)

---



## Yisong's Comments

1. GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding. ICLR'19 Alex Wang1 , Amanpreet Singh1 , Julian Michael2 , Felix Hill3 , Omer Levy2 & Samuel R. Bowman1 [Local copy](files/glue.pdf)

   This paper has a few takeaways summarized by me:

   > However, this model still achieves a fairly low absolute score. Analysis with our diagnostic dataset reveals that our baseline models deal well with strong lexical signals but struggle with deeper logical structure.

   



